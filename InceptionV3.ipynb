{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3cb118-ee5d-46ba-81c1-eaa8d492add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "train_dir = 'COP_banknote/ds3/Train'\n",
    "test_dir = 'COP_banknote/ds3/Test'\n",
    "validation_dir = 'COP_banknote/ds3/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9d2586-0060-49ea-b606-d9b4d82136fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 20:42:41.827556: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-21 20:42:41.828789: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-21 20:42:41.847695: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-21 20:42:41.847708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-21 20:42:41.847728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 20:42:41.851822: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-21 20:42:41.852415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 20:42:42.249319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73a7f44-ba49-4ec7-a1b1-280d64440d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8600 images belonging to 12 classes.\n",
      "Found 2913 images belonging to 12 classes.\n",
      "Epoch 1/3\n",
      "269/269 [==============================] - 204s 751ms/step - loss: 0.7224 - accuracy: 0.7816 - val_loss: 0.2562 - val_accuracy: 0.9156\n",
      "Epoch 2/3\n",
      "269/269 [==============================] - 189s 701ms/step - loss: 0.2154 - accuracy: 0.9291 - val_loss: 0.1800 - val_accuracy: 0.9389\n",
      "Epoch 3/3\n",
      "269/269 [==============================] - 165s 613ms/step - loss: 0.1662 - accuracy: 0.9426 - val_loss: 0.0397 - val_accuracy: 0.9907\n",
      "Found 2903 images belonging to 12 classes.\n",
      "91/91 [==============================] - 19s 205ms/step - loss: 0.0397 - accuracy: 0.9945\n",
      "InceptionV3 Test accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Load the InceptionV3 model without the top layer (include_top=False)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(12, activation='softmax')(x)  # Use 'softmax' for multi-class classification\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers from the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),  # InceptionV3 input size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    classes=['100k', '100kf', '10k', '10kf', '50k', '50kf', '5k', '5kf', '20k', '20kf', '2k', '2kf']\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    classes=['100k', '100kf', '10k', '10kf', '50k', '50kf', '5k', '5kf', '20k', '20kf', '2k', '2kf']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=3,  # You can adjust the number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    classes=['100k', '100kf', '10k', '10kf', '50k', '50kf', '5k', '5kf', '20k', '20kf', '2k', '2kf']\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'InceptionV3 Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "# Save the trained model for later use\n",
    "model.save('banknote_inceptionv3_multiclass.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
